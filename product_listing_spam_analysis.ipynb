{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Marketplace App Challenge: Detecting Spam in Product Listings\n",
    "Summit Bhalla   \n",
    "Walkthrough of bag-of-words approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "file_path = os.path.dirname(os.path.realpath('__file__'))\n",
    "raw_train = os.path.join(file_path,'data/train_set.csv')\n",
    "raw_test = os.path.join(file_path, 'data/test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration & Cleaning\n",
    "_____\n",
    "- First look at the raw data in a beautified df :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(raw_train)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** ----Output Truncated for Data Privacy Purposes---- **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial observations:\n",
    "- Won't need the first index column as the DF will manage indices\n",
    "- (Obviously) the title and description will be predictive of spam / ham classification. My first impression is that the other fields hold less predictive power...\n",
    "- Immediately see missing values in the first entry. Will need to look for other missing values...\n",
    "- Text fields will need to be encoded in utf-8. Will only include text that is part of the ascii character set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        0\n",
       "product_id        1\n",
       "seller_id         1\n",
       "title             1\n",
       "description       1\n",
       "meet_up        7398\n",
       "mailing        7398\n",
       "condition      8417\n",
       "price             1\n",
       "class             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_features = df.isnull().sum()\n",
    "null_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There's at least one value that is null in each of the columns. That sucks.\n",
    "- There's a high number of nulls for the meet_up, mailing and condition features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>product_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>meet_up</th>\n",
       "      <th>mailing</th>\n",
       "      <th>condition</th>\n",
       "      <th>price</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  product_id  seller_id title description meet_up mailing  \\\n",
       "655         656         NaN        NaN   NaN         NaN     NaN     NaN   \n",
       "\n",
       "    condition  price  class  \n",
       "655       NaN    NaN    NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.product_id.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absolute Empty Values</th>\n",
       "      <th>Percentage Empty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seller_id</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meet_up</th>\n",
       "      <td>7398</td>\n",
       "      <td>64.336029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mailing</th>\n",
       "      <td>7398</td>\n",
       "      <td>64.336029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <td>8417</td>\n",
       "      <td>73.197669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Absolute Empty Values  Percentage Empty\n",
       "Unnamed: 0                       0          0.000000\n",
       "product_id                       1          0.008696\n",
       "seller_id                        1          0.008696\n",
       "title                            1          0.008696\n",
       "description                      1          0.008696\n",
       "meet_up                       7398         64.336029\n",
       "mailing                       7398         64.336029\n",
       "condition                     8417         73.197669\n",
       "price                            1          0.008696\n",
       "class                            1          0.008696"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove empty column\n",
    "df = df[df.product_id.notnull()]\n",
    "\n",
    "null_stats = pd.concat([null_features, null_features/len(df.index)*100], axis=1)\n",
    "null_stats.columns = ['Absolute Empty Values', 'Percentage Empty']\n",
    "null_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thankfully there was only one rogue empty column which was removed. Order is now restored.\n",
    "- The proportion of empty values in fields: 'meet_up', 'mailing' and 'condition' is too high to be relied upon for information. It'll only contribute noise to our model so we'll drop these features.\n",
    "-----\n",
    "#### We'll now use these observations to setup our training / cross-validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_input(csv_path):\n",
    "    \n",
    "    include_cols = ['product_id','seller_id','title','description','price','class']\n",
    "    data = pd.read_csv(csv_path, usecols = include_cols, encoding = \"ISO-8859-1\")\n",
    "\n",
    "    #remove empty rows (based on null product_id)\n",
    "    data = data[data.product_id.notnull()]\n",
    "\n",
    "    # update title and description fields to include ascii characters\n",
    "    text_fields = ['title','description']\n",
    "    data[text_fields] = data[text_fields].applymap(lambda text: text.encode('ascii','ignore').decode('ascii'))\n",
    "\n",
    "    #random shuffle of rows within the training set (redistribute ordering of spam/ham examples)\n",
    "    shuffled = data.iloc[np.random.permutation(len(data))]\n",
    "    data = shuffled.reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "traincv = clean_input(raw_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "----\n",
    "- Now that we have clean training data, we'll now explore if additional features (of value) can be extracted \n",
    "- First thought is description length..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnIAAAFWCAYAAADt+3AoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD58heno5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1166d0e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "traincv['desc_length'] = traincv['description'].map(lambda text: len(text))\n",
    "_ = traincv.boxplot(vert=False, column=['desc_length'], by=['class'], return_type='axes',figsize=(10,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class       \n",
       "0      count    10218.000000\n",
       "       mean       278.841946\n",
       "       std        283.720245\n",
       "       min          1.000000\n",
       "       25%         95.000000\n",
       "       50%        185.000000\n",
       "       75%        341.750000\n",
       "       max       2043.000000\n",
       "1      count     1281.000000\n",
       "       mean      1681.684621\n",
       "       std       2089.110528\n",
       "       min         57.000000\n",
       "       25%        530.000000\n",
       "       50%       1012.000000\n",
       "       75%       1829.000000\n",
       "       max      12561.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traincv.groupby('class')['desc_length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More observations:\n",
    "- Skewed classes in training set (1281 spam vs 102018 ham examples)\n",
    "- The character length for spam listings is higher with much wider spread. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traincv[traincv['class'] == 1].groupby(['seller_id','class']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ----Output Truncated for Data Privacy Purposes---- **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My Feature Extraction Wish List (things I would explore further given more time)...\n",
    "- Explore repeat users who spam (seems to be quite a few people - see cell above)\n",
    "- Look at price distribution, there are a number of outliers (large price values) classified as spam.\n",
    "    - Would also normalize price values to 0 mean and unit variance\n",
    "- Seems like most \"tags\" are at the end of description messages. Find a way to capture this information.\n",
    "\n",
    "For now, I'll move on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Feature Extraction\n",
    "---------\n",
    "-  We'll try modeling the binary classifier with a bag-of-words approach using the term frequency-inverse document frequency (TF-IDF) feature representation. \n",
    "- *Aside*: It's worth noting the TF-IDF feature vector ignores word orders that carry syntactic and semantic relationships. An RNN model could be explored here, but might not be required given structure of spam text examples and the small training dataset. \n",
    "- We'll use scikit learn's Pipeline library to extract text features (n-grams) from input and (evenually) combine features for classification.\n",
    "- We'll do this now so it'll be easier for us to swap text feature extractors, feature transformations and classifiers.\n",
    "- It'll also be more advantaguous during hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating pipeline of text feature extractors, transformers for classification\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer',  CountVectorizer()),\n",
    "    ('tfidf',  TfidfTransformer()),\n",
    "    #('clf',  MultinomialNB()) ])\n",
    "    ('clf',  SGDClassifier()) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation\n",
    "---------\n",
    "- Since the number of available training data is low, we'll avoid using using a hold-out validation set and go with k-fold cross-validation\n",
    "- Selecting k=7 as the validation fold would equal ~15% of training set for each k iterations. Would like to have higher variance to start with (especially with a simple classifier) and adjust accordingly. \n",
    "-------\n",
    "- First train/CV run using the product listing description text as feature (unigram) and linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0] ROC AUC Score: 0.89992\n",
      "[fold 1] ROC AUC Score: 0.85355\n",
      "[fold 2] ROC AUC Score: 0.85570\n",
      "[fold 3] ROC AUC Score: 0.86493\n",
      "[fold 4] ROC AUC Score: 0.85555\n",
      "[fold 5] ROC AUC Score: 0.86817\n",
      "[fold 6] ROC AUC Score: 0.86620\n",
      "\n",
      "Total listings classified: 11499\n",
      "Score: 0.86629\n",
      "Confusion matrix:\n",
      "[[10137    81]\n",
      " [  332   949]]\n"
     ]
    }
   ],
   "source": [
    "k_fold_cv = KFold(n_folds=7, n=len(traincv))\n",
    "scores = []\n",
    "confusion = np.array([[0, 0], [0, 0]])\n",
    "for k, (train_idx, val_idx) in enumerate(k_fold_cv):\n",
    "    # training folds to fit model\n",
    "    train_x = traincv.iloc[train_idx]['description'].values\n",
    "    train_y = traincv.iloc[train_idx]['class'].values\n",
    "    # validation fold to test model\n",
    "    val_x = traincv.iloc[val_idx]['description'].values\n",
    "    val_y = traincv.iloc[val_idx]['class'].values\n",
    "\n",
    "    pipeline.fit(train_x, train_y)\n",
    "    preds = pipeline.predict(val_x)\n",
    "\n",
    "    confusion += confusion_matrix(val_y, preds)\n",
    "    score = roc_auc_score(val_y, preds)\n",
    "    scores.append(score)\n",
    "    print(\"[fold {0}] ROC AUC Score: {1:.5f}\".format(k,score))\n",
    "\n",
    "print('\\nTotal listings classified: {0}'.format(len(traincv)) )\n",
    "print('Score: {0:.5f}'.format(sum(scores)/float(len(scores))) )\n",
    "print('Confusion matrix:')\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- The result was encouraging considering: \n",
    "    - Simple bag of words model captures limited word orders which carry syntactic and semantic relationships.  \n",
    "    - Only used one feature input - the *description* text field\n",
    "    - Using default hyperparameter values.  \n",
    "- Negative: There is a high proportion of false negatives (ham predictions that are actually spam). This will impact search relevancy.\n",
    "---------\n",
    "### Some important thoughts on Model Evaluation (in the context of the marketplace)\n",
    "- Low recall, or sensitivity, is undesired as it would affect the marketplace buyers' search relevancy (by returning unintended spam messages to buyers' search results). \n",
    "- However, it can be argued that **precision is more important to improving user experience** (avoiding false positives - blocking seller listings that are actually ham). We wouldn't want to block legitimate listings, just to stop others from doing so. Perhaps, we should prioritize what's most important from a marketplace / company standpoint...\n",
    "------\n",
    "- For this exercise, I'll be using the requested ROC AUC evaluation metric. However, considering we have a skewed dataset and the points made above, it would be advantagous to leverage the *precision-recall curve*. \n",
    "- In particular, we can look for the best classifiers with *max precision(r)* where *r = recall is \"acceptably high\" (eg. > 0.85)*. In other words, **if we're to prioritize the buyers' user experience (through reduction of false negatives), let's select a classifier threshold with the highest precision at \"acceptably high\" recall value.**\n",
    "- If this explanation is too complicated, we can simplify things and use the F2 score as an evaluation metric :)\n",
    "- That said, the ROC AUC metric is good starting point for an assignment like this\n",
    "---------\n",
    "- **Note:** Evaluation metrics and its prioritization is dependant on how the model would be rolled out. Would model inference be executed during search retrieval? Or when a user submits a listing? These details would affect how we would evaluate the model's performance.\n",
    "- It's also worth noting the problem could be framed differently than a binary decision problem. A ranking mechinism could be deployed (based on the posting's clarity and conciseness). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuning\n",
    "-------\n",
    "- We performed cross-validation using our pipeline with no changes to hyperparameters\n",
    "- We'll use scikit learn's grid search library so we can train and evaluate\n",
    "- Grid search CV also provides cross-validation support for free. We'll use the default 3 folds to minimize search time\n",
    "- Note: searching over a subset of parameters values (previously searched over all, but did not improve results given higher model complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vectorizer__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vectorizer__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    'clf__n_iter': (10, 50, 80),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "('pipeline:', ['vectorizer', 'tfidf', 'clf'])\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.968\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-05\n",
      "\tclf__n_iter: 50\n",
      "\tclf__penalty: 'elasticnet'\n",
      "\tvectorizer__max_df: 0.75\n",
      "\tvectorizer__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "spam_model = GridSearchCV(pipeline, parameters, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "\n",
    "train_x = traincv.description.values\n",
    "train_y = traincv['class'].values\n",
    "spam_model.fit(train_x, train_y)\n",
    "\n",
    "print(\"Best score: %0.3f\" % spam_model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = spam_model.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10199,    19],\n",
       "       [   25,  1256]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix on training dataset\n",
    "predictions = spam_model.predict(train_x)\n",
    "cm = confusion_matrix(train_y, predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at an example of training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = train_x[np.not_equal(train_y,predictions)]\n",
    "print(\"random error example: %s \" % (np.random.choice(error,1)[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ----Output Truncated for Data Privacy Purposes---- **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick observations:\n",
    "- Combining other features to the model could improve performance\n",
    "    - As seen above, incorporating description length could help\n",
    "    - Increase weighting on comma or hashtag characters\n",
    "\n",
    "### (Immediate) Further Improvements:\n",
    "- Include other features (title, price, description length, misspellings) into the model pipeline. \n",
    "    - This can be achieved using FeatureUnions and Custom Transformers in scikit learn.\n",
    "        - Example: Title n-gram counts to be fed into tf-idf transformer, and (normalized) price, desc_length etc. fed directly to the linear classifier. \n",
    "- Examine whether model is overfitting (first with deviance plots)\n",
    "- **Due to time constraints, I'll leave this as a future exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Model Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input test_set csv for cleaning\n",
    "test = clean_input(raw_test)\n",
    "test_x = test.description.values\n",
    "test_y = test['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC score: 0.89907\n",
      "Classifier Statistics:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.97      0.96      1423\n",
      "          1       0.90      0.83      0.86       407\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1830\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions on test set using best model from gs\n",
    "test_preds = spam_model.predict(test_x)\n",
    "test_score = roc_auc_score(test_y, test_preds)\n",
    "print(\"Test ROC AUC score: %0.5f\" % test_score)\n",
    "print(\"Classifier Statistics:\\n\")\n",
    "print(classification_report(test_y, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts on Production Deployments\n",
    "----\n",
    "- Can serialize the model to disk for use in production environments (see cell below)\n",
    "- Would have to consider model monitoring (capturing classifier stats logs, required notifications etc.)\n",
    "- Monitoring *\"distribution drift\"* \n",
    "    - If users catch on to filtering techniques, the distribution of features could change and hence the model would need to be updated accordingly. \n",
    "    - If the distribution changes rapidly, then perhaps an online learning model would be appropriate (instead of offline learning, online inference model as implemented here).\n",
    "- Determine reliability requirements such as fail-over, redundancy, load-balancing etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_file = os.path.join(file_path,'model/spam_predictor.pickle')\n",
    "\n",
    "with open(model_file, 'wb') as fout:\n",
    "    cPickle.dump(spam_model, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
